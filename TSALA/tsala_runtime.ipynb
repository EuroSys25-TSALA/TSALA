{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tcn import TCN, tcn_full_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def fetch_selected_data(source_db_path, table_name, selected_columns):\n",
    "    conn = sqlite3.connect(source_db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    columns_str = ','.join(selected_columns)\n",
    "    query = f\"SELECT {columns_str} FROM {table_name}\"\n",
    "    cursor.execute(query)\n",
    "\n",
    "    data = pd.DataFrame(cursor.fetchall(), columns=selected_columns)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_columns = ['progName', 'jobID', 'relativeStartTime','startMonthDaySin', 'startMonthDayCos', 'startDaytimeSin', 'startDaytimeCos',\n",
    "                    'runTime', 'numProc', 'numOST', 'stripeSize', 'totalFile', 'totalIOReq',\n",
    "                    'totalMetaReq', 'mdsCPUMean', 'mdsOPSMean', 'seqWritePct', 'seqReadPct', 'consecWritePct', 'consecReadpct', 'writeBytesTotal', 'readBytesTotal',\n",
    "                    'totalReadReq', 'totalWriteReq', 'totalOpenReq', 'totalSeekReq', 'totalStatReq']\n",
    "\n",
    "source_db_path = './total_final.db'\n",
    "table_name = 'total_final'\n",
    "data = fetch_selected_data(source_db_path, table_name, selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for columns that has numeric data remove data under 0\n",
    "numeric_columns = data.iloc[:, data.columns.get_loc('runTime'):].select_dtypes(include=['int', 'float']).columns\n",
    "data_positive = data[(data[numeric_columns] > 0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trigono_columns = ['startMonthDaySin', 'startMonthDayCos', 'startDaytimeSin', 'startDaytimeCos']\n",
    "\n",
    "relativeStartTime_max = data_positive['relativeStartTime'].max()\n",
    "min_val_runtime = 0\n",
    "max_val_runtime = 0\n",
    "for column in data_positive.columns[2:]:\n",
    "    if column in trigono_columns:\n",
    "        # (value + 1) /2\n",
    "        data_positive[column] = (data_positive[column] + 1.0) / 2.0\n",
    "    elif column == 'relativeStartTime':\n",
    "        # proportion of time regards to max end time\n",
    "        data_positive[column] = data_positive[column] / relativeStartTime_max\n",
    "    elif column == 'stripeSize':\n",
    "        # rank scaling\n",
    "        data_positive['stripeSizeRank'] = data_positive['stripeSize'].rank(method='average')\n",
    "        data_positive['stripeSize'] = (data_positive['stripeSizeRank'] - 1) / (len(data_positive['stripeSize']) - 1)\n",
    "        data_positive.drop('stripeSizeRank', axis=1, inplace=True)\n",
    "    else:\n",
    "        # log(x+0.01) transformation\n",
    "        data_positive[column] = np.log(data_positive[column] + 0.01)\n",
    "        # min-max normalization\n",
    "        min_val = data_positive[column].min()\n",
    "        max_val = data_positive[column].max()\n",
    "        data_positive[column] = (data_positive[column] - min_val) / (max_val - min_val)\n",
    "        if column == 'runTime':\n",
    "            min_val_runtime = min_val\n",
    "            max_val_runtime = max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_positive = data_positive[data_positive['runTime'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encode 'progName' to int\n",
    "data_positive['progName_encoded'] = data_positive['progName'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data_positive.drop(['runTime','progName', 'jobID', 'progName_encoded'], axis=1).values\n",
    "X_progName = data_positive['progName_encoded'].values\n",
    "y = data_positive['runTime'].values\n",
    "\n",
    "# use first 80% as training data\n",
    "split_index = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "X_progName_train, X_progName_test = X_progName[:split_index], X_progName[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_index = int(len(X_train) * 0.8)\n",
    "X_train, X_valid = X_train[:split_index], X_train[split_index:]\n",
    "X_progName_train, X_progName_valid = X_progName_train[:split_index], X_progName_train[split_index:]\n",
    "y_train, y_valid = y_train[:split_index], y_train[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_sequences(X, X_progName, y, sequence_length):\n",
    "    X_seq, progName_seq, y_seq = [], [], []\n",
    "\n",
    "    for i in range(len(X) - sequence_length + 1):\n",
    "        X_seq.append(X[i:(i + sequence_length)])\n",
    "        progName_seq.append(X_progName[i:(i + sequence_length)])\n",
    "        y_seq.append(y[i + sequence_length - 1])\n",
    "        \n",
    "    return np.array(X_seq), np.array(progName_seq), np.array(y_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Input, Embedding, Concatenate, Concatenate\n",
    "from keras.metrics import MeanAbsolutePercentageError, MeanAbsoluteError\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def build_model(sequence_length, n_features, progName_size, embedding_dim):\n",
    "\n",
    "    numeric_input = Input(shape=(sequence_length, n_features), name='numeric_input')\n",
    "    progName_input = Input(shape=(sequence_length,), name='progName_input')\n",
    "    progName_embedding = Embedding(input_dim=progName_size+1, output_dim=embedding_dim, input_length=sequence_length)(progName_input)\n",
    "    \n",
    "    combined_input = Concatenate(axis=-1)([progName_embedding, numeric_input])\n",
    "\n",
    "    tcn_output = TCN(padding='causal', return_sequences=False)(combined_input)\n",
    "  \n",
    "    # tcn_output = Dropout(0.05)(tcn_output)\n",
    "    \n",
    "    output = Dense(1, activation='linear')(tcn_output)\n",
    "\n",
    "    model = Model(inputs=[progName_input, numeric_input], outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# directory for saving model\n",
    "model_dir = 'saved_models'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "sequence_lengths = 40\n",
    "n_features = X_train.shape[1]\n",
    "progName_size = data_positive['progName'].nunique()\n",
    "embedding_dim = 30\n",
    "\n",
    "# early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# transform data to sequence\n",
    "X_train_seq, X_progName_train_seq, y_train_seq = create_sequences(X_train, X_progName_train, y_train, sequence_length)\n",
    "X_valid_seq, X_progName_valid_seq,  y_valid_seq = create_sequences(X_valid, X_progName_valid, y_valid, sequence_length)\n",
    "X_test_seq, X_progName_test_seq, y_test_seq = create_sequences(X_test, X_progName_test, y_test, sequence_length)\n",
    "\n",
    "model = build_model(sequence_length, n_features, progName_size, embedding_dim)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\",\n",
    "              metrics=MeanAbsolutePercentageError())\n",
    "model.fit([X_progName_train_seq, X_train_seq], y_train_seq, \n",
    "          epochs = 100,\n",
    "          validation_data=([X_progName_valid_seq, X_valid_seq], y_valid_seq), \n",
    "          callbacks=[early_stopping])\n",
    "\n",
    "eval_result = model.evaluate([X_progName_test_seq, X_test_seq], y_test_seq)\n",
    "current_mse = eval_result[0]\n",
    "current_mape = eval_result[1]\n",
    "print(f\"Sequence length {sequence_length} MSE: {current_mae} MAPE: {current_mape}\")\n",
    "\n",
    "model_path = os.path.join(model_dir, f\"tsala_runtime.h5\")\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test_seq, X_progName_test_seq, y_test_seq = create_sequences(X_test, X_progName_test, y_test, best_sequence_length)\n",
    "predicted_data = best_model.predict([X_progName_test_seq, X_test_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r_squared = r2_score(y_test_seq, predicted_data)\n",
    "print(f'R2: {r_squared: .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_y_true = reverse_transform(y_test_seq, min_val_runtime, max_val_runtime)\n",
    "original_y_predict = reverse_transform(np.array(predicted_data), min_val_runtime, max_val_runtime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.9.0",
   "language": "python",
   "name": "tensorflow-2.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
